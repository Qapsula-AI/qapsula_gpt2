from typing import List, Dict, Tuple
from ..llm.llm_base import BaseLLM
from ..schemas import Document


class Generator:
    """Generator –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self, llm: BaseLLM):
        self.llm = llm
    
    def _create_rag_prompt(
        self,
        query: str,
        documents: List[Tuple[Document, float]]
    ) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è RAG —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        if not documents:
            return query
        
        context_parts = []
        for i, (doc, score) in enumerate(documents, 1):
            context_parts.append(f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}]\n{doc.content}\n")
        
        context = "\n".join(context_parts)
        
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
- –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
- –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
- –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –∏ —Ç–æ—á–Ω—ã–º

–û—Ç–≤–µ—Ç:"""
        
        return prompt
    
    async def generate(
        self,
        query: str,
        documents: List[Tuple[Document, float]],
        chat_history: List[Dict[str, str]] = None
    ) -> str:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            documents: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å scores
            chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
        
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        prompt = self._create_rag_prompt(query, documents)
        response = await self.llm.generate(
            prompt=prompt,
            context=chat_history,
            max_tokens=1000
        )
        return response
    
    async def generate_without_context(
        self,
        query: str,
        chat_history: List[Dict[str, str]] = None
    ) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –±–µ–∑ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        print(f"ü§ñ Generator: –Ω–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        print(f"üìù Generator: –∑–∞–ø—Ä–æ—Å: {query[:50]}...")
        response = await self.llm.generate(
            prompt=query,
            context=chat_history,
            max_tokens=100  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        )
        print(f"‚úÖ Generator: –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({len(response)} —Å–∏–º–≤–æ–ª–æ–≤)")
        return response
