"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ RAG –∏–Ω—Å—Ç–∞–Ω—Å–∞–º–∏.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º—É–ª—å—Ç–∏—Ç–µ–Ω–∞–Ω—Ç–Ω–æ—Å—Ç—å - –∫–∞–∂–¥—ã–π –∫–ª–∏–µ–Ω—Ç –∏–º–µ–µ—Ç —Å–≤–æ—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.
"""
import os
from typing import Dict, Optional
from pathlib import Path
import yaml

from app.rag.rag_pipeline import RAGPipeline
from app.rag.rag_retriever import Retriever
from app.rag.rag_generator import Generator
from app.rag.rag_ingest import DocumentIngestor
from app.vectorstore.vectorstore_faiss import FAISSVectorStore
from app.llm.llm_openrouter import OpenRouterLLM
from app.llm.llm_openai import OpenAILLM
from app.llm.llm_llamacpp import LlamaCppLLM, SaigaLlamaCppLLM, MistralLlamaCppLLM


class RAGManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä RAG –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏—Ç–µ–Ω–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
    Singleton - —Å–æ–∑–¥–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
    """
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern - —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞."""
        if self._initialized:
            return
        
        self._pipelines: Dict[str, RAGPipeline] = {}
        self._llms: Dict[str, any] = {}
        self._vectorstores: Dict[str, FAISSVectorStore] = {}
        self._initialized = True
        
        print("üîß RAG Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def initialize_tenant(
        self,
        tenant_id: str,
        config: Optional[dict] = None,
        force_reload: bool = False
    ) -> RAGPipeline:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG pipeline –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.
        
        Args:
            tenant_id: ID –∫–ª–∏–µ–Ω—Ç–∞ (client1, client2, default, etc.)
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ (–µ—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞)
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
        
        Returns:
            RAGPipeline –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        """
        # –ï—Å–ª–∏ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
        if tenant_id in self._pipelines and not force_reload:
            print(f"‚úÖ RAG –¥–ª—è '{tenant_id}' —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return self._pipelines[tenant_id]
        
        print(f"\n{'='*60}")
        print(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞: {tenant_id}")
        print(f"{'='*60}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if config is None:
            config = self._load_tenant_config(tenant_id)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞
        base_data_dir = Path(os.getenv("DATA_DIR", "./data"))
        tenant_data_dir = base_data_dir / tenant_id
        documents_path = tenant_data_dir / "documents"
        vectorstore_path = tenant_data_dir / "vectorstore"
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        documents_path.mkdir(parents=True, exist_ok=True)
        vectorstore_path.parent.mkdir(parents=True, exist_ok=True)
        
        print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö: {tenant_data_dir}")
        print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã: {documents_path}")
        print(f"üíæ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {vectorstore_path}")
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
        llm = await self._initialize_llm(tenant_id, config)
        self._llms[tenant_id] = llm
        
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        vectorstore = await self._initialize_vectorstore(
            tenant_id=tenant_id,
            documents_path=documents_path,
            vectorstore_path=vectorstore_path
        )
        self._vectorstores[tenant_id] = vectorstore
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ RAG Pipeline
        retriever = Retriever(
            vectorstore=vectorstore,
            top_k=config.get('top_k', 3)
        )
        
        generator = Generator(
            llm=llm,
            system_prompt=config.get('system_prompt')
        )
        
        pipeline = RAGPipeline(
            retriever=retriever,
            generator=generator,
            use_rag_threshold=config.get('rag_threshold', 0.5)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self._pipelines[tenant_id] = pipeline
        
        print(f"{'='*60}")
        print(f"‚úÖ RAG –¥–ª—è '{tenant_id}' –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        print(f"{'='*60}\n")
        
        return pipeline
    
    async def _initialize_llm(self, tenant_id: str, config: dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞."""
        llm_type = config.get('llm_type', 'openrouter')
        
        print(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM (—Ç–∏–ø: {llm_type})...")
        
        if llm_type == 'openrouter':
            api_key = config.get('api_key') or os.getenv('OPENROUTER_API_KEY')
            if not api_key:
                raise ValueError(f"OPENROUTER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {tenant_id}")
            
            model = config.get('model', 'openai/gpt-4o-mini')
            print(f"   –ú–æ–¥–µ–ª—å: {model}")
            
            return OpenRouterLLM(
                model_name=model,
                api_key=api_key,
                temperature=config.get('temperature', 0.7),
                max_tokens=config.get('max_tokens', 1000),
                extra_headers={
                    "X-Title": f"qapsula_gpt2_{tenant_id}",
                    "HTTP-Referer": os.getenv("OPENROUTER_REFERER", "")
                }
            )
        
        elif llm_type == 'openai':
            api_key = config.get('api_key') or os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise ValueError(f"OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {tenant_id}")
            
            model = config.get('model', 'gpt-4')
            print(f"   –ú–æ–¥–µ–ª—å: {model}")
            
            return OpenAILLM(
                model_name=model,
                api_key=api_key,
                temperature=config.get('temperature', 0.7),
                max_tokens=config.get('max_tokens', 1000)
            )
        
        elif llm_type == 'local':
            model_path = config.get('model_path')
            if not model_path:
                raise ValueError(f"model_path –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è {tenant_id}")
            
            model_type = config.get('model_type', 'saiga')
            n_gpu_layers = config.get('n_gpu_layers', 0)
            
            print(f"   –ú–æ–¥–µ–ª—å: {model_path}")
            print(f"   –¢–∏–ø: {model_type}")
            print(f"   GPU layers: {n_gpu_layers}")
            
            if model_type == 'saiga':
                return SaigaLlamaCppLLM(
                    model_path=model_path,
                    n_gpu_layers=n_gpu_layers,
                    temperature=config.get('temperature', 0.7),
                    n_ctx=config.get('n_ctx', 4096)
                )
            elif model_type == 'mistral':
                return MistralLlamaCppLLM(
                    model_path=model_path,
                    n_gpu_layers=n_gpu_layers,
                    temperature=config.get('temperature', 0.7),
                    n_ctx=config.get('n_ctx', 4096)
                )
            else:
                return LlamaCppLLM(
                    model_path=model_path,
                    n_gpu_layers=n_gpu_layers,
                    temperature=config.get('temperature', 0.7),
                    n_ctx=config.get('n_ctx', 4096)
                )
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø LLM: {llm_type}")
    
    async def _initialize_vectorstore(
        self,
        tenant_id: str,
        documents_path: Path,
        vectorstore_path: Path
    ) -> FAISSVectorStore:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞."""
        print(f"üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
        
        vectorstore = FAISSVectorStore()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        index_path = vectorstore_path.with_suffix('.index')
        
        if index_path.exists():
            print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
            await vectorstore.load(str(vectorstore_path))
            
            try:
                count = vectorstore.index.ntotal
                print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {count} –≤–µ–∫—Ç–æ—Ä–æ–≤")
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤: {e}")
        
        else:
            print(f"üÜï –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            if documents_path.exists():
                doc_files = list(documents_path.glob("*"))
                doc_files = [f for f in doc_files if f.suffix in ['.txt', '.md', '.pdf', '.docx']]
                
                if doc_files:
                    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_files)}")
                    
                    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
                    ingestor = DocumentIngestor(vectorstore)
                    total_chunks = await ingestor.ingest_directory(
                        str(documents_path),
                        extensions=[".txt", ".md", ".pdf", ".docx"]
                    )
                    
                    print(f"‚úì –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {total_chunks} —á–∞–Ω–∫–æ–≤")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                    await vectorstore.save(str(vectorstore_path))
                    print(f"üíæ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
                else:
                    print(f"‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {documents_path}")
                    print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—É—Å—Ç–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
            else:
                print(f"‚ö†Ô∏è  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—É—Å—Ç–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
        
        return vectorstore
    
    def _load_tenant_config(self, tenant_id: str) -> dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ YAML —Ñ–∞–π–ª–∞
        base_data_dir = Path(os.getenv("DATA_DIR", "./data"))
        config_path = base_data_dir / tenant_id / "config.yaml"
        
        if config_path.exists():
            print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ {config_path}")
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ .env
        print(f"üìÑ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ .env")
        
        return {
            'llm_type': os.getenv('LLM_TYPE', 'openrouter'),
            'model': os.getenv('OPENROUTER_MODEL', 'openai/gpt-4o-mini'),
            'api_key': None,  # –ë—É–¥–µ—Ç –≤–∑—è—Ç –∏–∑ .env –≤ _initialize_llm
            'temperature': float(os.getenv('TEMPERATURE', '0.7')),
            'max_tokens': int(os.getenv('MAX_TOKENS', '1000')),
            'top_k': int(os.getenv('RAG_TOP_K', '3')),
            'rag_threshold': float(os.getenv('USE_RAG_THRESHOLD', '0.5')),
            'system_prompt': None
        }
    
    def get_pipeline(self, tenant_id: str) -> Optional[RAGPipeline]:
        """–ü–æ–ª—É—á–∏—Ç—å RAG pipeline –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞."""
        return self._pipelines.get(tenant_id)
    
    def get_llm(self, tenant_id: str):
        """–ü–æ–ª—É—á–∏—Ç—å LLM –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞."""
        return self._llms.get(tenant_id)
    
    def get_vectorstore(self, tenant_id: str) -> Optional[FAISSVectorStore]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞."""
        return self._vectorstores.get(tenant_id)
    
    def list_tenants(self) -> list:
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
        return list(self._pipelines.keys())
    
    async def reload_tenant(self, tenant_id: str) -> RAGPipeline:
        """
        –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å RAG pipeline –∫–ª–∏–µ–Ω—Ç–∞.
        –ü–æ–ª–µ–∑–Ω–æ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
        """
        print(f"üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ RAG –¥–ª—è '{tenant_id}'...")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã
        if tenant_id in self._pipelines:
            del self._pipelines[tenant_id]
        if tenant_id in self._llms:
            del self._llms[tenant_id]
        if tenant_id in self._vectorstores:
            del self._vectorstores[tenant_id]
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–Ω–æ–≤–æ
        return await self.initialize_tenant(tenant_id, force_reload=True)
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
        stats = {
            'total_tenants': len(self._pipelines),
            'tenants': {}
        }
        
        for tenant_id, pipeline in self._pipelines.items():
            try:
                vectorstore_size = pipeline.retriever.vectorstore.index.ntotal
            except:
                vectorstore_size = 0
            
            stats['tenants'][tenant_id] = {
                'vectorstore_size': vectorstore_size,
                'llm_type': type(self._llms.get(tenant_id)).__name__,
                'status': 'active'
            }
        
        return stats