"""FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏ API."""
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import asyncio

from app.rag.rag_pipeline import RAGPipeline
from app.llm.llm_openrouter import OpenRouterLLM


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="Telegram RAG Bot API",
    description="API –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è RAG –±–æ—Ç–æ–º",
    version="1.0.0"
)

# CORS –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# === Pydantic –º–æ–¥–µ–ª–∏ ===

class ChatRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å —á–∞—Ç–∞."""
    message: str
    user_id: Optional[str] = "api_user"
    use_rag: bool = True


class ChatResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —á–∞—Ç–∞."""
    response: str
    sources: Optional[List[str]] = None
    tokens_used: Optional[int] = None


class DocumentUpload(BaseModel):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    content: str
    title: str
    metadata: Optional[dict] = None


class HealthResponse(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è."""
    status: str
    version: str
    vectorstore_size: int


# === –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ) ===
rag_pipeline: Optional[RAGPipeline] = None
llm: Optional[OpenRouterLLM] = None


# === –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ===

@app.get("/", tags=["General"])
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç."""
    return {
        "message": "Telegram RAG Bot API",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse, tags=["General"])
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞."""
    vectorstore_size = 0
    if rag_pipeline and rag_pipeline.retriever:
        try:
            vectorstore_size = rag_pipeline.retriever.vectorstore.index.ntotal
        except:
            pass
    
    return {
        "status": "healthy",
        "version": "1.0.0",
        "vectorstore_size": vectorstore_size
    }


@app.post("/chat", response_model=ChatResponse, tags=["Chat"])
async def chat(request: ChatRequest):
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É –∏ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.
    
    - **message**: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
    - **user_id**: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - **use_rag**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG –∏–ª–∏ –Ω–µ—Ç
    """
    if not rag_pipeline:
        raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        if request.use_rag:
            response = await rag_pipeline.process_query(
                query=request.message,
                chat_history=[]  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é
            )
        else:
            # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ LLM –±–µ–∑ RAG
            response = await llm.generate(request.message)
        
        return {
            "response": response,
            "sources": None,  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            "tokens_used": None
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/documents/upload", tags=["Documents"])
async def upload_document(doc: DocumentUpload, background_tasks: BackgroundTasks):
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
    
    - **content**: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
    - **title**: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    - **metadata**: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    """
    if not rag_pipeline:
        raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
    
    try:
        from app.schemas import Document
        from app.rag.rag_ingest import DocumentIngestor
        
        # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç
        document = Document(
            content=doc.content,
            metadata={
                "title": doc.title,
                "source": "api_upload",
                **(doc.metadata or {})
            }
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ —Ñ–æ–Ω–µ
        ingestor = DocumentIngestor(rag_pipeline.retriever.vectorstore)
        
        async def ingest_task():
            chunks = await ingestor.ingest_document(document)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            import os
            vector_store_path = os.getenv("VECTOR_STORE_PATH", "./data/vectorstore")
            await rag_pipeline.retriever.vectorstore.save(vector_store_path)
            return chunks
        
        background_tasks.add_task(ingest_task)
        
        return {
            "status": "processing",
            "message": f"–î–æ–∫—É–º–µ–Ω—Ç '{doc.title}' –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å –∑–∞–≥—Ä—É–∑–∫–∏"
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/documents/search", tags=["Documents"])
async def search_documents(query: str, k: int = 3):
    """
    –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    - **query**: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    - **k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    if not rag_pipeline:
        raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
    
    try:
        results = await rag_pipeline.retriever.retrieve(query, k=k)
        
        return {
            "query": query,
            "results": [
                {
                    "content": doc.content,
                    "metadata": doc.metadata,
                    "score": doc.metadata.get("score", 0)
                }
                for doc in results
            ]
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/stats", tags=["Statistics"])
async def get_statistics():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–æ—Ç–∞."""
    vectorstore_size = 0
    if rag_pipeline and rag_pipeline.retriever:
        try:
            vectorstore_size = rag_pipeline.retriever.vectorstore.index.ntotal
        except:
            pass
    
    return {
        "vectorstore": {
            "total_vectors": vectorstore_size,
            "model": "sentence-transformers/all-MiniLM-L6-v2"
        },
        "llm": {
            "provider": "OpenRouter",
            "model": "openai/gpt-4o-mini"
        }
    }


# === –°–æ–±—ã—Ç–∏—è –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ ===

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ."""
    global rag_pipeline, llm
    
    print("üöÄ –ó–∞–ø—É—Å–∫ FastAPI —Å–µ—Ä–≤–µ—Ä–∞...")
    
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG pipeline
    # (–∏–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ main_app.py)
    
    print("‚úÖ FastAPI —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤")


@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ."""
    print("üëã –û—Å—Ç–∞–Ω–æ–≤–∫–∞ FastAPI —Å–µ—Ä–≤–µ—Ä–∞...")